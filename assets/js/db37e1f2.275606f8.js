"use strict";(self.webpackChunkai_blog=self.webpackChunkai_blog||[]).push([[373],{3905:(e,t,a)=>{a.d(t,{Zo:()=>p,kt:()=>h});var n=a(7294);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function i(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function o(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?i(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):i(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function l(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},i=Object.keys(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var s=n.createContext({}),c=function(e){var t=n.useContext(s),a=t;return e&&(a="function"==typeof e?e(t):o(o({},t),e)),a},p=function(e){var t=c(e.components);return n.createElement(s.Provider,{value:t},e.children)},u="mdxType",m={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},g=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,i=e.originalType,s=e.parentName,p=l(e,["components","mdxType","originalType","parentName"]),u=c(a),g=r,h=u["".concat(s,".").concat(g)]||u[g]||m[g]||i;return a?n.createElement(h,o(o({ref:t},p),{},{components:a})):n.createElement(h,o({ref:t},p))}));function h(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var i=a.length,o=new Array(i);o[0]=g;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l[u]="string"==typeof e?e:r,o[1]=l;for(var c=2;c<i;c++)o[c]=a[c];return n.createElement.apply(null,o)}return n.createElement.apply(null,a)}g.displayName="MDXCreateElement"},5955:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>s,contentTitle:()=>o,default:()=>m,frontMatter:()=>i,metadata:()=>l,toc:()=>c});var n=a(7462),r=(a(7294),a(3905));const i={slug:"action",title:"Beyond to Action Recognition; A Survey on Advanced Video Understanding",authors:["seulgi"],tags:["Survey","Action Recognition"]},o=void 0,l={permalink:"/ai-blog/blog/action",source:"@site/blog/survey/2022-08-31-action.md",title:"Beyond to Action Recognition; A Survey on Advanced Video Understanding",description:"Goal of this post is to investigate Action Detection datasets such as AVA Action and AVA-Kinetics, as well as the Homage Dataset.",date:"2022-08-31T00:00:00.000Z",formattedDate:"August 31, 2022",tags:[{label:"Survey",permalink:"/ai-blog/blog/tags/survey"},{label:"Action Recognition",permalink:"/ai-blog/blog/tags/action-recognition"}],readingTime:1.33,hasTruncateMarker:!0,authors:[{name:"SeulGi Hong",title:"Vision AI Engineer",url:"https://github.com/sghong977",imageURL:"https://avatars.githubusercontent.com/u/46152199?v=4",key:"seulgi"}],frontMatter:{slug:"action",title:"Beyond to Action Recognition; A Survey on Advanced Video Understanding",authors:["seulgi"],tags:["Survey","Action Recognition"]},prevItem:{title:"Trends on September 2022",permalink:"/ai-blog/blog/2209"},nextItem:{title:"mmdetection; change scheduler, ensemble",permalink:"/ai-blog/blog/detection5"}},s={authorsImageUrls:[void 0]},c=[{value:"My notes...",id:"my-notes",level:3}],p={toc:c},u="wrapper";function m(e){let{components:t,...a}=e;return(0,r.kt)(u,(0,n.Z)({},p,a,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("p",null,"Goal of this post is to investigate ",(0,r.kt)("strong",{parentName:"p"},"Action Detection")," datasets such as AVA Action and AVA-Kinetics, as well as the Homage Dataset."),(0,r.kt)("h1",{id:"\ub0b4\uc6a9"},"\ub0b4\uc6a9"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},"Explore ActivityNet Challenges")),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Conducted initial research to grasp the trends by examining various datasets and tasks related to video understanding."),(0,r.kt)("li",{parentName:"ul"},"findings: I Decided to look into ",(0,r.kt)("strong",{parentName:"li"},"AVA-Kinetics and Homage"),".")),(0,r.kt)("p",null,"By the way, since 2019 that SlowFast won ActivityNet Challenges, Chinese groups have been consistently securing the 1st place in 20, 21, and 22."),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"This year (2022) focuses on active speaker detection, which is different due to the use of audio."),(0,r.kt)("li",{parentName:"ul"},"1st place: ",(0,r.kt)("a",{parentName:"li",href:"https://unicon-asd.github.io/"},"Project Page"),", Code to be released."),(0,r.kt)("li",{parentName:"ul"},"2nd place by Intel: ",(0,r.kt)("a",{parentName:"li",href:"https://arxiv.org/pdf/2112.01479.pdf"},"Paper"))),(0,r.kt)("ol",{start:2},(0,r.kt)("li",{parentName:"ol"},"About AVA-Kinetics")),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Spatio-Temporal Action Localization Task"),(0,r.kt)("li",{parentName:"ul"},"Research on state-of-the-art (SOTA): ",(0,r.kt)("a",{parentName:"li",href:"https://paperswithcode.com/sota/spatio-temporal-action-localization-on-ava"},"paperswithcode"),", ",(0,r.kt)("a",{parentName:"li",href:"http://activity-net.org/challenges/2022/tasks/guest_ava.html"},"List of AVA Challenge Winners")),(0,r.kt)("li",{parentName:"ul"},'"RM" outperformed the ACAR-Net (CVPR 2021 paper) which is a winning model of AVA Action (ActivityNet Challenge 2020)',(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"RM: This model won the AVA-Kinetics 2021 Challenge. ",(0,r.kt)("a",{parentName:"li",href:"https://arxiv.org/pdf/2106.08061v2.pdf"},"paper"),", but the GitHub code is not available.")))),(0,r.kt)("p",null,(0,r.kt)("img",{parentName:"p",src:"https://user-images.githubusercontent.com/46152199/187596772-d0f79cc1-7b11-4586-bc10-5b0ea1ffa58a.png",alt:"image"})),(0,r.kt)("ol",{start:3},(0,r.kt)("li",{parentName:"ol"},"About Homage")),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"About Model")),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"It seems meaningless to search for SOTA on paperswithcode as there are no notable models reported."),(0,r.kt)("li",{parentName:"ul"},"Official GitHub page provides detailed information about the dataset ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/nishantrai18/homage"},"github")),(0,r.kt)("li",{parentName:"ul"},"Let's check the challenge results. ",(0,r.kt)("a",{parentName:"li",href:"https://homeactiongenome.org/results.html"},"2021 Results")),(0,r.kt)("li",{parentName:"ul"},"The 2022 results seem unavailable as the challenge ended in June. Challenge Page on ",(0,r.kt)("a",{parentName:"li",href:"https://codalab.lisn.upsaclay.fr/competitions/4264#results"},"CodaLab"))),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"About Data")),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Dataset Paper ",(0,r.kt)("a",{parentName:"li",href:"https://arxiv.org/pdf/2105.05226.pdf"},"link"),(0,r.kt)("img",{parentName:"li",src:"https://user-images.githubusercontent.com/46152199/187603295-1125faef-9a98-4c42-ad85-56f745269e55.png",alt:"image"}))),(0,r.kt)("h3",{id:"my-notes"},"My notes..."),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://ambitious-posong.tistory.com/121"},"my blog")),(0,r.kt)("li",{parentName:"ul"},"During the survey, I came across this: MIGS (BMVC 2021) ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/migs2021/migs"},"GitHub"),".",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Although it doesn't use the Homage dataset, it is listed on paperswithcode.")))))}m.isMDXComponent=!0}}]);