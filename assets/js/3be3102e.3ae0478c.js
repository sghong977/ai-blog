"use strict";(self.webpackChunkai_blog=self.webpackChunkai_blog||[]).push([[6854],{3905:(e,t,n)=>{n.d(t,{Zo:()=>c,kt:()=>g});var r=n(7294);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function a(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,r,o=function(e,t){if(null==e)return{};var n,r,o={},i=Object.keys(e);for(r=0;r<i.length;r++)n=i[r],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(r=0;r<i.length;r++)n=i[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var s=r.createContext({}),u=function(e){var t=r.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):a(a({},t),e)),n},c=function(e){var t=u(e.components);return r.createElement(s.Provider,{value:t},e.children)},p="mdxType",m={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},d=r.forwardRef((function(e,t){var n=e.components,o=e.mdxType,i=e.originalType,s=e.parentName,c=l(e,["components","mdxType","originalType","parentName"]),p=u(n),d=o,g=p["".concat(s,".").concat(d)]||p[d]||m[d]||i;return n?r.createElement(g,a(a({ref:t},c),{},{components:n})):r.createElement(g,a({ref:t},c))}));function g(e,t){var n=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var i=n.length,a=new Array(i);a[0]=d;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l[p]="string"==typeof e?e:o,a[1]=l;for(var u=2;u<i;u++)a[u]=n[u];return r.createElement.apply(null,a)}return r.createElement.apply(null,n)}d.displayName="MDXCreateElement"},869:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>s,contentTitle:()=>a,default:()=>m,frontMatter:()=>i,metadata:()=>l,toc:()=>u});var r=n(7462),o=(n(7294),n(3905));const i={slug:"detection5",title:"mmdetection; change scheduler, ensemble",authors:"seulgi",tags:["Research Note","Object Detection","VIPrior"]},a=void 0,l={permalink:"/ai-blog/blog/detection5",source:"@site/blog/research-note/challenge-vipriors/2022-08-29-detection5.md",title:"mmdetection; change scheduler, ensemble",description:"Episode 5 for my VIPrior challenge journey link!",date:"2022-08-29T00:00:00.000Z",formattedDate:"August 29, 2022",tags:[{label:"Research Note",permalink:"/ai-blog/blog/tags/research-note"},{label:"Object Detection",permalink:"/ai-blog/blog/tags/object-detection"},{label:"VIPrior",permalink:"/ai-blog/blog/tags/vi-prior"}],readingTime:1.23,hasTruncateMarker:!0,authors:[{name:"SeulGi Hong",title:"Vision AI Engineer",url:"https://github.com/sghong977",imageURL:"https://avatars.githubusercontent.com/u/46152199?v=4",key:"seulgi"}],frontMatter:{slug:"detection5",title:"mmdetection; change scheduler, ensemble",authors:"seulgi",tags:["Research Note","Object Detection","VIPrior"]},prevItem:{title:"Beyond to Action Recognition; A Survey on Advanced Video Understanding",permalink:"/ai-blog/blog/action"},nextItem:{title:"mmdetection YOLOX; image encoder transfer learning",permalink:"/ai-blog/blog/detection4"}},s={authorsImageUrls:[void 0]},u=[{value:"Using this",id:"using-this",level:3},{value:"Error",id:"error",level:3},{value:"Debug",id:"debug",level:3},{value:"Situation",id:"situation",level:3}],c={toc:u},p="wrapper";function m(e){let{components:t,...n}=e;return(0,o.kt)(p,(0,r.Z)({},c,n,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("p",null,"Episode 5 for my VIPrior challenge journey ",(0,o.kt)("a",{parentName:"p",href:"https://vipriors.github.io/"},"link"),"!"),(0,o.kt)("h1",{id:"issue-1-change-scheduler"},"Issue 1. change scheduler"),(0,o.kt)("h3",{id:"using-this"},"Using this"),(0,o.kt)("p",null,"mmclassification doc. ",(0,o.kt)("a",{parentName:"p",href:"https://mmclassification.readthedocs.io/en/master/_modules/mmcls/core/hook/lr_updater.html#CosineAnnealingCooldownLrUpdaterHook"},"link")),(0,o.kt)("h3",{id:"error"},"Error"),(0,o.kt)("p",null,"Error Message"),(0,o.kt)("blockquote",null,(0,o.kt)("p",{parentName:"blockquote"},"../aten/src/ATen/native/cuda/Loss.cu:115: operator(): block: ","[176,0,0]",", thread: ","[108,0,0]"," Assertion ","`","input_val >= zero && input_val <= one","`"," failed.")),(0,o.kt)("h3",{id:"debug"},"Debug"),(0,o.kt)("p",null,"Seems like a loss scale issue due to lr, so I re-enabled auto_lr."),(0,o.kt)("p",null,"Reference: ",(0,o.kt)("a",{parentName:"p",href:"https://discuss.pytorch.org/t/assertion-input-val-zero-input-val-one-failed/107554/3"},"https://discuss.pytorch.org/t/assertion-input-val-zero-input-val-one-failed/107554/3")),(0,o.kt)("p",null,"FYI: There is a feature to receive ",(0,o.kt)("strong",{parentName:"p"},"notifications via email or Slack")," in case of crashes or completion of training."),(0,o.kt)("p",null,(0,o.kt)("img",{parentName:"p",src:"https://user-images.githubusercontent.com/46152199/187104173-d19d8404-3479-4caa-baa4-5c28d58db66b.png",alt:"image"})),(0,o.kt)("h1",{id:"issue-2-ensemble"},"Issue 2. Ensemble"),(0,o.kt)("p",null,"I investigated and summarized it on my blog: ",(0,o.kt)("a",{parentName:"p",href:"https://ambitious-posong.tistory.com/201"},"Link, kor")),(0,o.kt)("p",null,"The tool provided there takes image inputs, but there is no need to perform inference several times. Therefore, I will receive JSON files and code for ensemble."),(0,o.kt)("p",null,"Requirements"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Reference Code: ",(0,o.kt)("a",{parentName:"li",href:"https://github.com/ZFTurbo/Weighted-Boxes-Fusion"},"https://github.com/ZFTurbo/Weighted-Boxes-Fusion")),(0,o.kt)("li",{parentName:"ul"},"output1: /raid/sghong/Detection/mmdetection/work_dirs/yoloxx_0826/inferences/bbox.json"),(0,o.kt)("li",{parentName:"ul"},"output2: /nas4/viprior/sbhong/yoloxx/mmcls/submission.json")),(0,o.kt)("h3",{id:"situation"},"Situation"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"need to provide only bbox, category id, and score to Weighted-Boxes-Fusion."),(0,o.kt)("li",{parentName:"ul"},"Perform ensemble for each image and save the results (the order should not change due to the submission format)."),(0,o.kt)("li",{parentName:"ul"},"Consensus will be added, similar to preprocessing as described in my blog.")),(0,o.kt)("p",null,"Keep using my Docker environment used for running the detection. The only thing I need for these ensemble is:\n",(0,o.kt)("inlineCode",{parentName:"p"},"pip install ensemble-boxes"),"."),(0,o.kt)("p",null,"Implementation"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Using the ensemble-boxes module"),(0,o.kt)("li",{parentName:"ul"},"Take multiple JSON inference results as input -> perform ensemble -> then write the results as JSON."),(0,o.kt)("li",{parentName:"ul"},"Follow the 2022 VIPriors Object Detection Challenge submission format."),(0,o.kt)("li",{parentName:"ul"},"Consensus or other preprocessing(?) will be implemented tomorrow....")),(0,o.kt)("p",null,"My code link: ",(0,o.kt)("a",{parentName:"p",href:"https://github.com/sghong977/Daily_AIML/blob/fc4eede51557f6870e70939c54f9db855a3f6741/Object_Detection/ensemble.py"},"https://github.com/sghong977/Daily_AIML/blob/fc4eede51557f6870e70939c54f9db855a3f6741/Object_Detection/ensemble.py")))}m.isMDXComponent=!0}}]);