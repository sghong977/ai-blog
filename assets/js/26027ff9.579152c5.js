"use strict";(self.webpackChunkai_blog=self.webpackChunkai_blog||[]).push([[3311],{3905:(e,t,a)=>{a.d(t,{Zo:()=>u,kt:()=>h});var l=a(7294);function n(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function i(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);t&&(l=l.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,l)}return a}function r(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?i(Object(a),!0).forEach((function(t){n(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):i(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function o(e,t){if(null==e)return{};var a,l,n=function(e,t){if(null==e)return{};var a,l,n={},i=Object.keys(e);for(l=0;l<i.length;l++)a=i[l],t.indexOf(a)>=0||(n[a]=e[a]);return n}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(l=0;l<i.length;l++)a=i[l],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(n[a]=e[a])}return n}var s=l.createContext({}),p=function(e){var t=l.useContext(s),a=t;return e&&(a="function"==typeof e?e(t):r(r({},t),e)),a},u=function(e){var t=p(e.components);return l.createElement(s.Provider,{value:t},e.children)},m="mdxType",c={inlineCode:"code",wrapper:function(e){var t=e.children;return l.createElement(l.Fragment,{},t)}},k=l.forwardRef((function(e,t){var a=e.components,n=e.mdxType,i=e.originalType,s=e.parentName,u=o(e,["components","mdxType","originalType","parentName"]),m=p(a),k=n,h=m["".concat(s,".").concat(k)]||m[k]||c[k]||i;return a?l.createElement(h,r(r({ref:t},u),{},{components:a})):l.createElement(h,r({ref:t},u))}));function h(e,t){var a=arguments,n=t&&t.mdxType;if("string"==typeof e||n){var i=a.length,r=new Array(i);r[0]=k;var o={};for(var s in t)hasOwnProperty.call(t,s)&&(o[s]=t[s]);o.originalType=e,o[m]="string"==typeof e?e:n,r[1]=o;for(var p=2;p<i;p++)r[p]=a[p];return l.createElement.apply(null,r)}return l.createElement.apply(null,a)}k.displayName="MDXCreateElement"},3936:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>s,contentTitle:()=>r,default:()=>c,frontMatter:()=>i,metadata:()=>o,toc:()=>p});var l=a(7462),n=(a(7294),a(3905));const i={slug:"mshot",title:"Multishot Human Pose",authors:"seulgi",tags:["Research Note","SMPL","3D Human Pose","Pose Estimation","PHALP","MultiShot","OpenPose"]},r=void 0,o={permalink:"/ai-blog/blog/mshot",source:"@site/blog/research-note/2023-04-05-mshot.md",title:"Multishot Human Pose",description:"I'm trying to extract SMPL parameters on video in a multishot setting. To this end, tracklets are necessary.",date:"2023-04-05T00:00:00.000Z",formattedDate:"April 5, 2023",tags:[{label:"Research Note",permalink:"/ai-blog/blog/tags/research-note"},{label:"SMPL",permalink:"/ai-blog/blog/tags/smpl"},{label:"3D Human Pose",permalink:"/ai-blog/blog/tags/3-d-human-pose"},{label:"Pose Estimation",permalink:"/ai-blog/blog/tags/pose-estimation"},{label:"PHALP",permalink:"/ai-blog/blog/tags/phalp"},{label:"MultiShot",permalink:"/ai-blog/blog/tags/multi-shot"},{label:"OpenPose",permalink:"/ai-blog/blog/tags/open-pose"}],readingTime:3.09,hasTruncateMarker:!0,authors:[{name:"SeulGi Hong",title:"Vision AI Engineer",url:"https://github.com/sghong977",imageURL:"https://avatars.githubusercontent.com/u/46152199?v=4",key:"seulgi"}],frontMatter:{slug:"mshot",title:"Multishot Human Pose",authors:"seulgi",tags:["Research Note","SMPL","3D Human Pose","Pose Estimation","PHALP","MultiShot","OpenPose"]},prevItem:{title:"Annoying Settings",permalink:"/ai-blog/blog/settings"},nextItem:{title:"LERF; Language Embedded Radiance Fields",permalink:"/ai-blog/blog/lerf"}},s={authorsImageUrls:[void 0]},p=[{value:"Steps",id:"steps",level:3},{value:"Summary of PHALP",id:"summary-of-phalp",level:3},{value:"Installation",id:"installation",level:3},{value:"Settings",id:"settings",level:3},{value:"Settings",id:"settings-1",level:3},{value:"Pre-processing",id:"pre-processing",level:3},{value:"Optimization",id:"optimization",level:3},{value:"Notes.",id:"notes",level:3}],u={toc:p},m="wrapper";function c(e){let{components:t,...a}=e;return(0,n.kt)(m,(0,l.Z)({},u,a,{components:t,mdxType:"MDXLayout"}),(0,n.kt)("p",null,"I'm trying to extract SMPL parameters on video in a multishot setting. To this end, tracklets are necessary."),(0,n.kt)("h3",{id:"steps"},"Steps"),(0,n.kt)("p",null,"PHALP setup -> Multishot Human Pose extraction -> select data for training NeRF."),(0,n.kt)("h1",{id:"1-phalp-setup"},"1. PHALP setup"),(0,n.kt)("h3",{id:"summary-of-phalp"},"Summary of PHALP"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},'"Tracking People by Predicting 3D Appearance, Location & Pose" (CVPR 2022)'),(0,n.kt)("li",{parentName:"ul"},"Input: monocular video"),(0,n.kt)("li",{parentName:"ul"},"Task: Tracking people"),(0,n.kt)("li",{parentName:"ul"},"Method",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"lift people in a frame to 3D (3D pose of human, human location in 3D space, 3D appearance)"),(0,n.kt)("li",{parentName:"ul"},"track a person: collect 3D observations over time in a tracklet representation -> build temporal model",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"model predict the ",(0,n.kt)("strong",{parentName:"li"},"future state of a tracklet including 3d location, pose, appearance")),(0,n.kt)("li",{parentName:"ul"},"for the future frame, calculate similarity between pred state of tracklet and single frame observations"))),(0,n.kt)("li",{parentName:"ul"},"Association: simple Hungarian matching"))),(0,n.kt)("li",{parentName:"ul"},"Output: *.pkl file (input for the next step, multishot human pose extraction)"),(0,n.kt)("li",{parentName:"ul"},"project page: ",(0,n.kt)("a",{parentName:"li",href:"http://people.eecs.berkeley.edu/~jathushan/PHALP/"},"PHALP project"))),(0,n.kt)("h3",{id:"installation"},"Installation"),(0,n.kt)("p",null,(0,n.kt)("strong",{parentName:"p"},"Tips")),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"about branch",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"master",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"pros: compatible to Mshot (CVPR22), relatively easy to install"),(0,n.kt)("li",{parentName:"ul"},"cons: out-dated, hard-coded"))),(0,n.kt)("li",{parentName:"ul"},"v1.1",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"pros: fancy code and demos"),(0,n.kt)("li",{parentName:"ul"},"cons: OpenGL and OSMesa would be a little bit tricky, not compatible to Mshot repo.",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("ol",{parentName:"li"},(0,n.kt)("li",{parentName:"ol"},"output *.pkl file should be slightly changed"))),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("ol",{parentName:"li",start:2},(0,n.kt)("li",{parentName:"ol"},"this demo code doesn't generate instance segmentation mask per person, which is necessary to Mshot preprocessing."))))))))),(0,n.kt)("li",{parentName:"ul"},"My settings",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"docker container / without conda"),(0,n.kt)("li",{parentName:"ul"},"off-screen",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"Pyrenderer and OpenGL may cause problems, you need to choose EGL or OSMesa"),(0,n.kt)("li",{parentName:"ul"},"I build OSMesa and use PyOpenGL + OSMesa combination. (check 'Failure Logs...' under)"))),(0,n.kt)("li",{parentName:"ul"},"works on PHALP master and v1.1 branches, and also work for Mshot."),(0,n.kt)("li",{parentName:"ul"},"Here is pip list output of my environment. ",(0,n.kt)("a",{parentName:"li",href:"https://github.com/sghong977/sghong977.github.io/files/11197975/req.txt"},"req.txt"))))),(0,n.kt)("details",null,(0,n.kt)("summary",null," Failure Logs... (skip this) "),(0,n.kt)("p",null,"Logs"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"follow this ",(0,n.kt)("a",{parentName:"li",href:"https://github.com/brjathu/PHALP#installation"},"PHALP")),(0,n.kt)("li",{parentName:"ul"},"it takes quite a time to solve environment in conda..."),(0,n.kt)("li",{parentName:"ul"},"\"('Connection broken: OSError(\"(104, \\'ECONNRESET\\')\")', OSError(\"(104, 'ECONNRESET')\"))\" error"),(0,n.kt)("li",{parentName:"ul"},"I'm using docker container",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"to install git+http, 'apt-get install git'"),(0,n.kt)("li",{parentName:"ul"},"pycocotools error: ",(0,n.kt)("a",{parentName:"li",href:"https://stackoverflow.com/questions/72611914/error-could-not-build-wheels-for-pycocotools-which-is-required-to-install-pypr"},"link")))),(0,n.kt)("li",{parentName:"ul"},"torch.ao is added on 1.10")),(0,n.kt)("p",null,"I tried setting an environment without conda, but failed. issues while installing PHALP:"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"pip install pyrootutils submitit gdown dill colordict scenedetect pytube"),(0,n.kt)("li",{parentName:"ul"},"pip install scikit-learn==0.22.2"),(0,n.kt)("li",{parentName:"ul"},"OpenGL: ssh env (without display)",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"install OSMesa ",(0,n.kt)("a",{parentName:"li",href:"https://pyrender.readthedocs.io/en/latest/install/index.html#installmesa"},"OSMesa doc")),(0,n.kt)("li",{parentName:"ul"},"apt-get install libexpat1-dev"))),(0,n.kt)("li",{parentName:"ul"},"encountered on PosixPath ~~~ error but I couldn't handle it"))),(0,n.kt)("hr",null),(0,n.kt)("h1",{id:"2-openpose"},"2. OpenPose"),(0,n.kt)("h3",{id:"settings"},"Settings"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"docker image from the hub: 'd0ckaaa/openpose'"),(0,n.kt)("li",{parentName:"ul"},"execute make commands to install"),(0,n.kt)("li",{parentName:"ul"},"download pretrained opencv models by get models script.")),(0,n.kt)("hr",null),(0,n.kt)("h1",{id:"3-multishot-human-pose-setup"},"3. multishot human pose setup"),(0,n.kt)("h3",{id:"settings-1"},"Settings"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"follow this ",(0,n.kt)("a",{parentName:"li",href:"https://github.com/geopavlakos/multishot#installation-instructions"},"multishot")),(0,n.kt)("li",{parentName:"ul"},"I use the same docker as the previous one."),(0,n.kt)("li",{parentName:"ul"},"Notes",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"use exactly the same version of smplx (if not, it may cause error)"),(0,n.kt)("li",{parentName:"ul"},"no need to use torch 1.5."),(0,n.kt)("li",{parentName:"ul"},"change environ variables: PYOPENGL_PLATFORM' egl \u2192 osmesa"),(0,n.kt)("li",{parentName:"ul"},"expand docker's shared memory size to 2GB"))),(0,n.kt)("li",{parentName:"ul"},"Data",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"download mshot_data from github official Mshot page (approximately 1GB)"),(0,n.kt)("li",{parentName:"ul"},"download smpl neutral pkl and gmm08 on the official smplify webpage and move to the correct location")))),(0,n.kt)("h3",{id:"pre-processing"},"Pre-processing"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("em",{parentName:"li"},".pkl \u2192 "),".npz"),(0,n.kt)("li",{parentName:"ul"},"output contains information for a specific person (create separately)"),(0,n.kt)("li",{parentName:"ul"},"these are the initial value of optimization step.")),(0,n.kt)("h3",{id:"optimization"},"Optimization"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"optimize the SMPL parameters using multishot loss")),(0,n.kt)("details",null,(0,n.kt)("summary",null," Memo "),(0,n.kt)("h3",{id:"notes"},"Notes."),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"To extract SMPL by multishot human pose, tracking and identification are needed."),(0,n.kt)("li",{parentName:"ul"},"What about the other SMPL algorithms? SMPL extraction models like ROMP, VIBE...",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"Do they use 2D keypoints?"),(0,n.kt)("li",{parentName:"ul"},"Regression or optimized based?"),(0,n.kt)("li",{parentName:"ul"},"How are they inputs like? sequence or only an image? should be cropped? do they work on multiple people?"),(0,n.kt)("li",{parentName:"ul"},"VIBE: ",(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/pdf/1912.05656.pdf"},"https://arxiv.org/pdf/1912.05656.pdf")),(0,n.kt)("li",{parentName:"ul"}))))))}c.isMDXComponent=!0}}]);